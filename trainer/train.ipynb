{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "1d32d083de5443e80ae33db15d1fd8896dae913c69d9faf431260a27bb617b64"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import config\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from tra_helper.plot_dset_one import plot_dset_one\n",
    "from models.unet import unet\n",
    "from models.unet_triple import unet_triple, unet_triple_v2\n",
    "from models.unet_gru_triple import unet_gru_triple\n",
    "import data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/yons/Desktop/developer-luo/SWatNet'\n",
    "## dataset\n",
    "tra_dset = data_loader.get_tra_dset()\n",
    "test_dset = data_loader.get_eva_dset()\n",
    "## training configuration\n",
    "loss_fun = config.binary_ce_loss\n",
    "optimizer = config.optimizer\n",
    "## model\n",
    "model = unet_gru_triple(scale_high=2048, scale_mid=512, scale_low=256, nclass=2, trainable_gru=False, trainable_unet=True)\n",
    "# model = unet_triple_v2(scale_high=2048, scale_mid=512, scale_low=256, nclass=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, loss_fun, optimizer, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pre,_,_,_ = model(x, training=True)\n",
    "        loss = loss_fun(y, y_pre)\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    config.tra_loss_tracker.update_state(loss)\n",
    "    config.tra_oa.update_state(y, y_pre)\n",
    "    config.tra_miou.update_state(y, y_pre)\n",
    "    return config.tra_loss_tracker.result(), config.tra_oa.result(), config.tra_miou.result()\n",
    "\n",
    "@tf.function\n",
    "def test_step(model, loss_fun, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pre,_,_,_ = model(x, training=False)\n",
    "        loss = loss_fun(y, y_pre)\n",
    "    config.test_loss_tracker.update_state(loss)\n",
    "    config.test_oa.update_state(y, y_pre)\n",
    "    config.test_miou.update_state(y, y_pre)\n",
    "    return config.test_loss_tracker.result(), config.test_oa.result(), config.test_miou.result()\n",
    "\n",
    "def train_loops(model, loss_fun, optimizer, tra_dset, test_dset, epochs):\n",
    "    max_miou_pre = 0.8\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time() \n",
    "        # train the model\n",
    "        for x_batch, y_batch in tra_dset:            \n",
    "            tra_loss_epoch,tra_oa_epoch,tra_miou_epoch = train_step(model, loss_fun, optimizer, x_batch, y_batch)\n",
    "        # test the model\n",
    "        for x_batch, y_batch in test_dset:\n",
    "            test_loss_epoch, test_oa_epoch, test_miou_epoch = test_step(model, loss_fun, x_batch, y_batch)\n",
    "        config.tra_loss_tracker.reset_states(), config.tra_oa.reset_states(), config.tra_miou.reset_states()\n",
    "        config.test_loss_tracker.reset_states(), config.test_oa.reset_states(), config.test_miou.reset_states()\n",
    "        # write into tensorboard\n",
    "        ## tensorboard writer\n",
    "        train_summary_writer = tf.summary.create_file_writer(config.train_log_dir)\n",
    "        test_summary_writer = tf.summary.create_file_writer(config.test_log_dir)\n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar('learning rate', data=config.optimizer.learning_rate(epoch*16), step=epoch)\n",
    "            tf.summary.scalar('loss', data=tra_loss_epoch, step=epoch)\n",
    "            tf.summary.scalar('oa', data=tra_oa_epoch, step=epoch)\n",
    "            tf.summary.scalar('miou', data=tra_miou_epoch, step=epoch)\n",
    "        with test_summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', data=test_loss_epoch, step=epoch)\n",
    "            tf.summary.scalar('oa', data=test_oa_epoch, step=epoch)\n",
    "            tf.summary.scalar('miou', data=test_miou_epoch, step=epoch)\n",
    "        # print the metrics\n",
    "        print('epoch {}: traLoss:{:.3f}, traOA:{:.2f}, traMIoU:{:.2f}; evaLoss:{:.3f}, evaOA:{:.2f}, evaMIoU:{:.2f}, time:{:.0f}s'.format(epoch + 1, tra_loss_epoch, tra_oa_epoch, tra_miou_epoch, test_loss_epoch, test_oa_epoch, test_miou_epoch, time.time() - start)) \n",
    "        if test_miou_epoch>max_miou_pre:\n",
    "            max_miou_pre = test_miou_epoch\n",
    "            model.save_weights(config.path_savedmodel+'/unet_gru_triple/weights_epoch_%d'%(epoch+1))\n",
    "        ## visualize the results.\n",
    "        if epoch%5 == 0:\n",
    "            figure = plot_dset_one(model, test_dset.take(1), i_img=np.random.randint(8),binary=True, weight=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training\n",
    "train_loops(model, loss_fun, optimizer, tra_dset, test_dset, epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# !kill 6006\n",
    "# %tensorboard --logdir logs/tensorb/\n",
    "# http://localhost:16006\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <dwconv_bn_relu.dwconv_bn_relu object at 0x7f3630062a90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <dwconv_bn_relu.dwconv_bn_relu object at 0x7f360c2c6fd0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <dwconv_bn_relu.dwconv_bn_relu object at 0x7f360c144048>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <conv_bn_relu.conv_bn_relu object at 0x7f360c070828>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <conv_bn_relu.conv_bn_relu object at 0x7f360c0f9048>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <conv_bn_relu.conv_bn_relu object at 0x7f35f47be748>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35f47be860>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f35f47bee10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f35f47c8198>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f360c136898>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f360c1369b0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f360c136908>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f360c2c63c8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f360c23d2e8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f360c23d518>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f360c144dd8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f360c1422e8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f360c142630>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f360c070940>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f360c070ef0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f360c08e278>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f360c0f9160>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f360c0f9710>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f360c0f9a58>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv_bn_relu_18_layer_call_fn, conv_bn_relu_18_layer_call_and_return_conditional_losses, dwconv_bn_relu_14_layer_call_fn, dwconv_bn_relu_14_layer_call_and_return_conditional_losses, conv2d_20_layer_call_fn while saving (showing 5 of 425). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv_bn_relu_18_layer_call_fn, conv_bn_relu_18_layer_call_and_return_conditional_losses, dwconv_bn_relu_14_layer_call_fn, dwconv_bn_relu_14_layer_call_and_return_conditional_losses, conv2d_20_layer_call_fn while saving (showing 5 of 425). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /home/yons/Desktop/developer-luo/SWatNet/models/pretrained/unet_gru_triple/assets\n",
      "INFO:tensorflow:Assets written to: /home/yons/Desktop/developer-luo/SWatNet/models/pretrained/unet_gru_triple/assets\n"
     ]
    }
   ],
   "source": [
    "# model saving and loading\n",
    "# path_weight = root_dir + '/models/temporal/UNet_gru_triple/weights_epoch_40'\n",
    "# path_save_model = root_dir + '/models/pretrained/unet_gru_triple'\n",
    "# model.save(path_save_model)\n",
    "# model.save_weights(path_model)\n",
    "# model = tf.keras.models.load_model(path_model)  ## load model\n",
    "# model.load_weights(path_weight)\n"
   ]
  }
 ]
}