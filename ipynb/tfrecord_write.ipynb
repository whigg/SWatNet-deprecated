{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "1d32d083de5443e80ae33db15d1fd8896dae913c69d9faf431260a27bb617b64"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/yons/Desktop/developer-luo/SWatNet\")\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from utils.tiff_io import readTiff\n",
    "from utils.imgPatch import imgPatch\n",
    "from utils.imgShow import imsShow\n",
    "from tfrecord.tfrecord_s1 import tfrecord_s1_scene, tfrecord_s1_patch\n",
    "import pprint as pp\n"
   ]
  },
  {
   "source": [
    "## Super-parameters configuration and get the data path"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "15\n5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "## data read path\n",
    "s1_ascend = root_dir + '/data/s1_ascend/*.tif'\n",
    "s1_descend = root_dir + '/data/s1_descend/*.tif'\n",
    "watTruth = root_dir + '/data/s2_img_truth/*_wat_truth.tif'\n",
    "## data write path\n",
    "traScene_file = root_dir + '/data/traScene.tfrecords'\n",
    "# traPatch_file = '/content/drive/My Drive/Sar_WaterExt_Data/traPatch_256_512_2048_100x.tfrecords'\n",
    "evaScene_file = root_dir + '/data/evaScene.tfrecords'\n",
    "evaPatch_file = root_dir + '/data/evaPatch_256_512_2048_100x.tfrecords'\n",
    "\n",
    "s1_ascend_path = sorted(tf.io.gfile.glob(s1_ascend))\n",
    "s1_descend_path = sorted(tf.io.gfile.glob(s1_descend))\n",
    "watTruth_path = sorted(tf.io.gfile.glob(watTruth))\n",
    "traScene_path = list(zip(s1_ascend_path, s1_descend_path, watTruth_path))[0:-5]\n",
    "print(len(traScene_path))\n",
    "evaScene_path = list(zip(s1_ascend_path, s1_descend_path, watTruth_path))[-5:]\n",
    "print(len(evaScene_path))"
   ]
  },
  {
   "source": [
    "## Write the training data (01-15) into tfrecord."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_traScene_ins = tfrecord_s1_scene()\n",
    "\n",
    "## 15/20(01-15) scenes for training\n",
    "### Write to a `.tfrecords` file for model training.\n",
    "with tf.io.TFRecordWriter(traScene_file) as writer:    \n",
    "    for s1_ascend_path, s1_descend_path, truth_water_path in traScene_path:\n",
    "        print(s1_ascend_path)\n",
    "        s1_ascend, _, _, _, _, _ = readTiff(s1_ascend_path)\n",
    "        s1_descend, _, _, _, _, _ = readTiff(s1_descend_path)\n",
    "        truth, _, _, _, _, _ = readTiff(truth_water_path)\n",
    "        ### normalization\n",
    "        s1_ascend_nor = (s1_ascend-np.nanmin(s1_ascend))/(np.nanmax(s1_ascend)-np.nanmin(s1_ascend))\n",
    "        s1_descend_nor = (s1_descend-np.nanmin(s1_descend))/(np.nanmax(s1_descend)-np.nanmin(s1_descend))\n",
    "        ### tfrecord writing\n",
    "        imsShow([s1_ascend_nor, s1_descend_nor, truth],['s1_ascend', 's1_descend', 's1_truth'],\\\n",
    "                                            [2,2,0], [(0,1,0),(0,1,0),(0,0,0)], figsize=(10,3))\n",
    "        tf_example = tfrecord_traScene_ins.scene_example_serilize(s1_ascend_nor, \\\n",
    "                                            s1_descend_nor, truth)\n",
    "        # writer.write(tf_example.SerializeToString())\n"
   ]
  },
  {
   "source": [
    "## Write the evaluation data (16-20) into the .tfrecord file."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfrecord_evaScene_ins = tfrecord_s1_scene()\n",
    "\n",
    "# ### Write scenes to a `.tfrecords` file.\n",
    "# ## 5/20(16,17,18,19,20) scenes for evaluation\n",
    "# with tf.io.TFRecordWriter(evaScene_file) as writer:  \n",
    "#     for s1_ascend_path, s1_descend_path, truth_water_path in evaScene_path:\n",
    "#         print(s1_ascend_path)\n",
    "#         s1_ascend, _, _, _, _, _ = readTiff(s1_ascend_path)\n",
    "#         s1_descend, _, _, _, _, _ = readTiff(s1_descend_path)\n",
    "#         truth, _, _, _, _, _ = readTiff(truth_water_path)\n",
    "#         s1_ascend_nor = (s1_ascend-np.nanmin(s1_ascend))/(np.nanmax(s1_ascend)-np.nanmin(s1_ascend))\n",
    "#         s1_descend_nor = (s1_descend-np.nanmin(s1_descend))/(np.nanmax(s1_descend)-np.nanmin(s1_descend))\n",
    "#         imsShow([s1_ascend_nor, s1_descend_nor, truth],['s1_ascend', 's1_descend','s1_truth'], \\\n",
    "#                                                 [2,2,0], [(0,1,0),(0,1,0),(0,0,0)], figsize=(10,3))\n",
    "#         tf_example = tfrecord_evaScene_ins.scene_example_serilize(s1_ascend_nor, \\\n",
    "#                                             s1_descend_nor, truth)\n",
    "#         writer.write(tf_example.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## write the training patches to a tfrecord file from scenes data\n",
    "# ##########################################\n",
    "# ### 1. load the training scenes and convert it to patches group. \n",
    "# tfrecord_scene_ins = tfrecord_s1_scene(scale_low = 256, scale_mid = 512, scale_high = 2048)\n",
    "# traScene = tf.data.TFRecordDataset(traScene_file)\n",
    "# traPatch = traScene.map(tfrecord_scene_ins.parse_sceneBand).map(tfrecord_scene_ins.parse_sceneShape)\\\n",
    "                                            # .map(tfrecord_scene_ins.toPatchGroup_fromScene)\n",
    "# print(traPatch)\n",
    "\n",
    "# ### 2. write the patches to a .tfrecord file.\n",
    "# tfrecord_patch_ins = tfrecord_s1_patch()\n",
    "# with tf.io.TFRecordWriter(traPatch_file) as writer:\n",
    "#     for i in range(100):\n",
    "#         print(i)\n",
    "#         for img_high, img_mid, img_low, truth_low in traPatch:\n",
    "#             imsShow([img_high, img_mid, img_low, truth_low], ['img_high', 'img_mid', 'img_low', 'truth_low'], \\\n",
    "#                                                 [2,2,2,0], [(2,1,0),(2,1,0),(2,1,0), (0,0,0)], figsize=(12,3))\n",
    "#             tf_example = tfrecord_patch_ins.patch_example_serilize(img_local.numpy(), truth_local.numpy(), img_global.numpy())\n",
    "#             writer.write(tf_example.SerializeToString())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write the evaluation patches to a tfrecord file from image scene data\n",
    "##########################################\n",
    "### 1. load the evaluation scenes and convert it to patches group.\n",
    "tfrecord_scene_ins = tfrecord_s1_scene(scale_low = 256, scale_mid = 512, scale_high = 2048)\n",
    "evaScene = tf.data.TFRecordDataset(evaScene_file)\n",
    "evaPatch = evaScene.map(tfrecord_scene_ins.parse_sceneSample, num_parallel_calls=tf.data.experimental.AUTOTUNE)\\\n",
    "            .map(tfrecord_scene_ins.parse_sceneShape, num_parallel_calls=tf.data.experimental.AUTOTUNE)\\\n",
    "            .map(tfrecord_scene_ins.toPatchGroup_fromScene, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "print(evaPatch)\n",
    "\n",
    "### 2. write the patches to a .tfrecord file.\n",
    "tfrecord_patch_ins = tfrecord_s1_patch()\n",
    "with tf.io.TFRecordWriter(evaPatch_file) as writer:\n",
    "    for i in range(100):\n",
    "        print(i)\n",
    "        for (img_high, img_mid, img_low), truth_low in evaPatch:\n",
    "            # imsShow([img_high, img_mid, img_low, truth_low],['img_high', 'img_mid', 'img_low', 'truth_low'], \\\n",
    "            #                                 [2,2,2,0], [(2,1,0),(2,1,0),(2,1,0), (0,0,0)], figsize=(12,3))\n",
    "            tf_example = tfrecord_patch_ins.patch_example_serilize(img_high.numpy(),\\\n",
    "                                            img_mid.numpy(),img_low.numpy(), truth_low.numpy())\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "\n"
   ]
  }
 ]
}